{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n",
      "[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n",
      "CartPole state: [ 0.01939038  0.04881888 -0.00071829  0.01545599]\n",
      "Iteration 0, Average reward 14.00, Epsilon 0.499\n",
      "Iteration 10, Average reward 12.45, Epsilon 0.495\n",
      "Iteration 20, Average reward 12.19, Epsilon 0.490\n",
      "Iteration 30, Average reward 12.71, Epsilon 0.485\n",
      "Iteration 40, Average reward 12.32, Epsilon 0.480\n",
      "Iteration 50, Average reward 12.37, Epsilon 0.475\n",
      "Iteration 60, Average reward 12.66, Epsilon 0.470\n",
      "Iteration 70, Average reward 12.79, Epsilon 0.466\n",
      "Iteration 80, Average reward 13.11, Epsilon 0.461\n",
      "Iteration 90, Average reward 12.98, Epsilon 0.456\n",
      "Iteration 100, Average reward 13.26, Epsilon 0.452\n",
      "Iteration 110, Average reward 13.32, Epsilon 0.447\n",
      "Iteration 120, Average reward 13.28, Epsilon 0.443\n",
      "Iteration 130, Average reward 13.18, Epsilon 0.439\n",
      "Iteration 140, Average reward 13.24, Epsilon 0.434\n",
      "Iteration 150, Average reward 13.19, Epsilon 0.430\n",
      "Iteration 160, Average reward 13.18, Epsilon 0.426\n",
      "Iteration 170, Average reward 13.06, Epsilon 0.421\n",
      "Iteration 180, Average reward 12.94, Epsilon 0.417\n",
      "Iteration 190, Average reward 12.87, Epsilon 0.413\n",
      "Iteration 200, Average reward 12.91, Epsilon 0.409\n",
      "Iteration 210, Average reward 12.95, Epsilon 0.405\n",
      "Iteration 220, Average reward 12.86, Epsilon 0.401\n",
      "Iteration 230, Average reward 12.77, Epsilon 0.397\n",
      "Iteration 240, Average reward 12.88, Epsilon 0.393\n",
      "Iteration 250, Average reward 12.84, Epsilon 0.389\n",
      "Iteration 260, Average reward 12.80, Epsilon 0.385\n",
      "Iteration 270, Average reward 12.78, Epsilon 0.381\n",
      "Iteration 280, Average reward 12.81, Epsilon 0.377\n",
      "Iteration 290, Average reward 12.79, Epsilon 0.374\n",
      "Iteration 300, Average reward 12.74, Epsilon 0.370\n",
      "Iteration 310, Average reward 12.73, Epsilon 0.366\n",
      "Iteration 320, Average reward 12.65, Epsilon 0.363\n",
      "Iteration 330, Average reward 12.61, Epsilon 0.359\n",
      "Iteration 340, Average reward 12.59, Epsilon 0.355\n",
      "Iteration 350, Average reward 12.55, Epsilon 0.352\n",
      "Iteration 360, Average reward 12.51, Epsilon 0.348\n",
      "Iteration 370, Average reward 12.50, Epsilon 0.345\n",
      "Iteration 380, Average reward 12.47, Epsilon 0.342\n",
      "Iteration 390, Average reward 12.46, Epsilon 0.338\n",
      "Iteration 400, Average reward 12.43, Epsilon 0.335\n",
      "Iteration 410, Average reward 12.45, Epsilon 0.331\n",
      "Iteration 420, Average reward 12.42, Epsilon 0.328\n",
      "Iteration 430, Average reward 12.39, Epsilon 0.325\n",
      "Iteration 440, Average reward 12.38, Epsilon 0.322\n",
      "Iteration 450, Average reward 12.36, Epsilon 0.318\n",
      "Iteration 460, Average reward 12.34, Epsilon 0.315\n",
      "Iteration 470, Average reward 12.34, Epsilon 0.312\n",
      "Iteration 480, Average reward 12.30, Epsilon 0.309\n",
      "Iteration 490, Average reward 12.26, Epsilon 0.306\n",
      "Iteration 500, Average reward 12.21, Epsilon 0.303\n",
      "Iteration 510, Average reward 12.18, Epsilon 0.300\n",
      "Iteration 520, Average reward 12.15, Epsilon 0.297\n",
      "Iteration 530, Average reward 12.12, Epsilon 0.294\n",
      "Iteration 540, Average reward 12.10, Epsilon 0.291\n",
      "Iteration 550, Average reward 12.08, Epsilon 0.288\n",
      "Iteration 560, Average reward 12.05, Epsilon 0.285\n",
      "Iteration 570, Average reward 12.06, Epsilon 0.282\n",
      "Iteration 580, Average reward 12.08, Epsilon 0.280\n",
      "Iteration 590, Average reward 12.06, Epsilon 0.277\n",
      "Iteration 600, Average reward 12.08, Epsilon 0.274\n",
      "Iteration 610, Average reward 12.07, Epsilon 0.271\n",
      "Iteration 620, Average reward 12.05, Epsilon 0.269\n",
      "Iteration 630, Average reward 12.04, Epsilon 0.266\n",
      "Iteration 640, Average reward 12.03, Epsilon 0.263\n",
      "Iteration 650, Average reward 12.00, Epsilon 0.261\n",
      "Iteration 660, Average reward 11.97, Epsilon 0.258\n",
      "Iteration 670, Average reward 11.95, Epsilon 0.256\n",
      "Iteration 680, Average reward 11.92, Epsilon 0.253\n",
      "Iteration 690, Average reward 11.92, Epsilon 0.250\n",
      "Iteration 700, Average reward 11.90, Epsilon 0.248\n",
      "Iteration 710, Average reward 11.90, Epsilon 0.245\n",
      "Iteration 720, Average reward 11.89, Epsilon 0.243\n",
      "Iteration 730, Average reward 11.88, Epsilon 0.241\n",
      "Iteration 740, Average reward 11.87, Epsilon 0.238\n",
      "Iteration 750, Average reward 11.86, Epsilon 0.236\n",
      "Iteration 760, Average reward 11.86, Epsilon 0.234\n",
      "Iteration 770, Average reward 11.85, Epsilon 0.231\n",
      "Iteration 780, Average reward 11.83, Epsilon 0.229\n",
      "Iteration 790, Average reward 11.82, Epsilon 0.227\n",
      "Iteration 800, Average reward 11.81, Epsilon 0.224\n",
      "Iteration 810, Average reward 11.78, Epsilon 0.222\n",
      "Iteration 820, Average reward 11.77, Epsilon 0.220\n",
      "Iteration 830, Average reward 11.76, Epsilon 0.218\n",
      "Iteration 840, Average reward 11.75, Epsilon 0.216\n",
      "Iteration 850, Average reward 11.74, Epsilon 0.213\n",
      "Iteration 860, Average reward 11.72, Epsilon 0.211\n",
      "Iteration 870, Average reward 11.70, Epsilon 0.209\n",
      "Iteration 880, Average reward 11.69, Epsilon 0.207\n",
      "Iteration 890, Average reward 11.67, Epsilon 0.205\n",
      "Iteration 900, Average reward 11.67, Epsilon 0.203\n",
      "Iteration 910, Average reward 11.66, Epsilon 0.201\n",
      "Iteration 920, Average reward 11.64, Epsilon 0.199\n",
      "Iteration 930, Average reward 11.64, Epsilon 0.197\n",
      "Iteration 940, Average reward 11.64, Epsilon 0.195\n",
      "Iteration 950, Average reward 11.63, Epsilon 0.193\n",
      "Iteration 960, Average reward 11.61, Epsilon 0.191\n",
      "Iteration 970, Average reward 11.61, Epsilon 0.189\n",
      "Iteration 980, Average reward 11.61, Epsilon 0.187\n",
      "Iteration 990, Average reward 11.59, Epsilon 0.186\n",
      "Iteration 1000, Average reward 11.58, Epsilon 0.184\n",
      "Iteration 1010, Average reward 11.57, Epsilon 0.182\n",
      "Iteration 1020, Average reward 11.55, Epsilon 0.180\n",
      "Iteration 1030, Average reward 11.54, Epsilon 0.178\n",
      "Iteration 1040, Average reward 11.53, Epsilon 0.176\n",
      "Iteration 1050, Average reward 11.52, Epsilon 0.175\n",
      "Iteration 1060, Average reward 11.50, Epsilon 0.173\n",
      "Iteration 1070, Average reward 11.49, Epsilon 0.171\n",
      "Iteration 1080, Average reward 11.48, Epsilon 0.170\n",
      "Iteration 1090, Average reward 11.47, Epsilon 0.168\n",
      "Iteration 1100, Average reward 11.46, Epsilon 0.166\n",
      "Iteration 1110, Average reward 11.45, Epsilon 0.165\n",
      "Iteration 1120, Average reward 11.44, Epsilon 0.163\n",
      "Iteration 1130, Average reward 11.44, Epsilon 0.161\n",
      "Iteration 1140, Average reward 11.44, Epsilon 0.160\n",
      "Iteration 1150, Average reward 11.43, Epsilon 0.158\n",
      "Iteration 1160, Average reward 11.42, Epsilon 0.156\n",
      "Iteration 1170, Average reward 11.41, Epsilon 0.155\n",
      "Iteration 1180, Average reward 11.41, Epsilon 0.153\n",
      "Iteration 1190, Average reward 11.40, Epsilon 0.152\n",
      "Iteration 1200, Average reward 11.39, Epsilon 0.150\n",
      "Iteration 1210, Average reward 11.37, Epsilon 0.149\n",
      "Iteration 1220, Average reward 11.37, Epsilon 0.147\n",
      "Iteration 1230, Average reward 11.36, Epsilon 0.146\n",
      "Iteration 1240, Average reward 11.35, Epsilon 0.144\n",
      "Iteration 1250, Average reward 11.34, Epsilon 0.143\n",
      "Iteration 1260, Average reward 11.33, Epsilon 0.142\n",
      "Iteration 1270, Average reward 11.33, Epsilon 0.140\n",
      "Iteration 1280, Average reward 11.32, Epsilon 0.139\n",
      "Iteration 1290, Average reward 11.31, Epsilon 0.137\n",
      "Iteration 1300, Average reward 11.30, Epsilon 0.136\n",
      "Iteration 1310, Average reward 11.29, Epsilon 0.135\n",
      "Iteration 1320, Average reward 11.28, Epsilon 0.133\n",
      "Iteration 1330, Average reward 11.26, Epsilon 0.132\n",
      "Iteration 1340, Average reward 11.26, Epsilon 0.131\n",
      "Iteration 1350, Average reward 11.25, Epsilon 0.129\n",
      "Iteration 1360, Average reward 11.24, Epsilon 0.128\n",
      "Iteration 1370, Average reward 11.23, Epsilon 0.127\n",
      "Iteration 1380, Average reward 11.22, Epsilon 0.126\n",
      "Iteration 1390, Average reward 11.21, Epsilon 0.124\n",
      "Iteration 1400, Average reward 11.20, Epsilon 0.123\n",
      "Iteration 1410, Average reward 11.19, Epsilon 0.122\n",
      "Iteration 1420, Average reward 11.18, Epsilon 0.121\n",
      "Iteration 1430, Average reward 11.18, Epsilon 0.119\n",
      "Iteration 1440, Average reward 11.17, Epsilon 0.118\n",
      "Iteration 1450, Average reward 11.16, Epsilon 0.117\n",
      "Iteration 1460, Average reward 11.15, Epsilon 0.116\n",
      "Iteration 1470, Average reward 11.14, Epsilon 0.115\n",
      "Iteration 1480, Average reward 11.14, Epsilon 0.114\n",
      "Iteration 1490, Average reward 11.13, Epsilon 0.112\n",
      "Iteration 1500, Average reward 11.13, Epsilon 0.111\n",
      "Iteration 1510, Average reward 11.12, Epsilon 0.110\n",
      "Iteration 1520, Average reward 11.12, Epsilon 0.109\n",
      "Iteration 1530, Average reward 11.11, Epsilon 0.108\n",
      "Iteration 1540, Average reward 11.11, Epsilon 0.107\n",
      "Iteration 1550, Average reward 11.10, Epsilon 0.106\n",
      "Iteration 1560, Average reward 11.10, Epsilon 0.105\n",
      "Iteration 1570, Average reward 11.09, Epsilon 0.104\n",
      "Iteration 1580, Average reward 11.09, Epsilon 0.103\n",
      "Iteration 1590, Average reward 11.07, Epsilon 0.102\n",
      "Iteration 1600, Average reward 11.07, Epsilon 0.101\n",
      "Iteration 1610, Average reward 11.06, Epsilon 0.100\n",
      "Iteration 1620, Average reward 11.05, Epsilon 0.099\n",
      "Iteration 1630, Average reward 11.04, Epsilon 0.098\n",
      "Iteration 1640, Average reward 11.04, Epsilon 0.097\n",
      "Iteration 1650, Average reward 11.03, Epsilon 0.096\n",
      "Iteration 1660, Average reward 11.02, Epsilon 0.095\n",
      "Iteration 1670, Average reward 11.01, Epsilon 0.094\n",
      "Iteration 1680, Average reward 11.01, Epsilon 0.093\n",
      "Iteration 1690, Average reward 11.00, Epsilon 0.092\n",
      "Iteration 1700, Average reward 10.99, Epsilon 0.091\n",
      "Iteration 1710, Average reward 10.98, Epsilon 0.090\n",
      "Iteration 1720, Average reward 10.97, Epsilon 0.089\n",
      "Iteration 1730, Average reward 10.96, Epsilon 0.088\n",
      "Iteration 1740, Average reward 10.96, Epsilon 0.088\n",
      "Iteration 1750, Average reward 10.95, Epsilon 0.087\n",
      "Iteration 1760, Average reward 10.94, Epsilon 0.086\n",
      "Iteration 1770, Average reward 10.94, Epsilon 0.085\n",
      "Iteration 1780, Average reward 10.93, Epsilon 0.084\n",
      "Iteration 1790, Average reward 10.92, Epsilon 0.083\n",
      "Iteration 1800, Average reward 10.91, Epsilon 0.082\n",
      "Iteration 1810, Average reward 10.91, Epsilon 0.082\n",
      "Iteration 1820, Average reward 10.90, Epsilon 0.081\n",
      "Iteration 1830, Average reward 10.89, Epsilon 0.080\n",
      "Iteration 1840, Average reward 10.89, Epsilon 0.079\n",
      "Iteration 1850, Average reward 10.88, Epsilon 0.078\n",
      "Iteration 1860, Average reward 10.88, Epsilon 0.078\n",
      "Iteration 1870, Average reward 10.87, Epsilon 0.077\n",
      "Iteration 1880, Average reward 10.86, Epsilon 0.076\n",
      "Iteration 1890, Average reward 10.85, Epsilon 0.075\n",
      "Iteration 1900, Average reward 10.85, Epsilon 0.075\n",
      "Iteration 1910, Average reward 10.84, Epsilon 0.074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1920, Average reward 10.83, Epsilon 0.073\n",
      "Iteration 1930, Average reward 10.83, Epsilon 0.072\n",
      "Iteration 1940, Average reward 10.83, Epsilon 0.072\n",
      "Iteration 1950, Average reward 10.82, Epsilon 0.071\n",
      "Iteration 1960, Average reward 10.82, Epsilon 0.070\n",
      "Iteration 1970, Average reward 10.81, Epsilon 0.070\n",
      "Iteration 1980, Average reward 10.81, Epsilon 0.069\n",
      "Iteration 1990, Average reward 10.80, Epsilon 0.068\n",
      "Reward of Test agent = 12.000\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import gym.spaces\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "from qlearning_template import QLearningAgent\n",
    "\n",
    "def discretize_range(lower_bound, upper_bound, num_bins):\n",
    "    return np.linspace(lower_bound, upper_bound, num_bins + 1)[1:-1]\n",
    "\n",
    "\n",
    "def discretize_value(value, bins):\n",
    "    return np.digitize(x=value, bins=bins)\n",
    "\n",
    "\n",
    "def build_state(observation):\n",
    "\t# you should use discretize_value() functions to build single state representation.\n",
    "    state = None\n",
    "\t\n",
    "    return state\n",
    "\n",
    "\n",
    "def play_and_train(env, agent, visualize=False, t_max=10 ** 4):\n",
    "    \"\"\"This function should\n",
    "    - run a full game, actions given by agent.get_action(s)\n",
    "    - train agent using agent.update(...) whenever possible\n",
    "    - return total reward\"\"\"\n",
    "    total_reward = 0.0\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "        d_s = build_state(s)\n",
    "\n",
    "        a = agent.get_action(d_s)\n",
    "\n",
    "        next_s, r, done, _ = env.step(a)\n",
    "        if visualize:\n",
    "            env.render()\n",
    "            time.sleep(0.05)\n",
    "        d_next_s = build_state(next_s)\n",
    "        agent.update(d_s, a, d_next_s, r)\n",
    "        s = next_s\n",
    "        total_reward += r\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    return total_reward\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    env = gym.make(\"CartPole-v0\").env\n",
    "    env.reset()\n",
    "    n_actions = env.action_space.n\n",
    "\n",
    "    print(env.observation_space.high)\n",
    "    print(env.observation_space.low)\n",
    "    print('CartPole state: %s' % (env.reset()))\n",
    "\n",
    "    agent = QLearningAgent(alpha = 0.3, get_legal_actions=lambda s: range(n_actions), epsilon=0.5, discount=1.0)\n",
    "\n",
    "    # (x, x', theta, theta')\n",
    "    state_bins = [  # Cart position.\n",
    "        discretize_range(-2.4, 2.4, 2),\n",
    "        # Cart velocity.\n",
    "        discretize_range(-3.0, 3.0, 2),\n",
    "        # Pole angle.\n",
    "        discretize_range(-0.5, 0.5, 7),\n",
    "        # Tip velocity.\n",
    "        discretize_range(-2.0, 2.0, 7)\n",
    "    ]\n",
    "    max_bins = max(len(bin) for bin in state_bins)\n",
    "\n",
    "    rewards = []\n",
    "    for i in range(2000):\n",
    "        rewards.append(play_and_train(env, agent))\n",
    "        agent.epsilon *= 0.999\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('Iteration {}, Average reward {:.2f}, Epsilon {:.3f}'.format(i, np.mean(rewards), agent.epsilon))\n",
    "\n",
    "    print('Reward of Test agent = %.3f' % play_and_train(env, agent, visualize=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
